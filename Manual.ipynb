{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即時數字辨識系統\n",
    "\n",
    "環境版本：Win10 python版本：3.9.9 \n",
    "\n",
    "桌面新增資料夾(MNIST-Live-Detection-TFLite-main)\n",
    "\n",
    "到：https://github.com/alankrantas/MNIST-Live-Detection-TFLite\n",
    "，下載：1. mnist.tflite 2. mnist_tflite_live_detection.py，將其放到資料夾內\n",
    "\n",
    "到終端機：pip3 install --upgrade numpy opencv-python\n",
    "\n",
    "到：https://github.com/google-coral/pycoral/releases/tag/v2.0.0\n",
    "，Win10 電腦使用 Python 3.9，就下載 tflite_runtime-2.5.0.post1-cp39-cp39-win_amd64.whl（cp39 代表 Python 3.9，amd64 即 x64）\n",
    "樹莓派 OS Buster 用 xxx-cp37-cp37m-linux_armv7l.whl（樹莓派 2~4B 為 ARMv8 架構）\n",
    "樹莓派 OS Bullseye 則用 xxx-cp39-cp39-linux_armv7l.whl，以此類推。\n",
    "\n",
    "將上一步驟下載的檔案放到同個資料夾內，到終端機進到該資料夾(cd Desktop\\MNIST-Live-Detection-TFLite-main)\n",
    "，終端機：pip3 install tflite_runtime-2.5.0.post1-cp39-cp39-win_amd64.whl\n",
    "\n",
    "最後接上webcam，終端機執行mnist_tflite_live_detection.py 即可進行即時數字辨識(按下q關閉程式)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "競爭對手：\n",
    "https://www.keyence.com.tw/landing/sensor/lp_vision-sensor_01123990.jsp?utm_medium=cpc&utm_content=KW-NB-CH-APP-IV-Core&aw=KW01kw0_10080242&gad=1&gclid=CjwKCAjwxr2iBhBJEiwAdXECw9JG8ed6vYps4LF3YqK-OrQpxzrOSr0Ge8N4i1AWI6PPHDH7eycVCRoCzYIQAvD_BwE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while(True):\n",
    "    # 擷取影像\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # 彩色轉灰階\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 顯示圖片\n",
    "    cv2.imshow('live', frame)\n",
    "    #cv2.imshow('live', gray)\n",
    "\n",
    "    # 按下 q 鍵離開迴圈\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# 釋放該攝影機裝置\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下方程式可運行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_MODEL = './mnist.tflite'  # TF Lite model\n",
    "IMG_W = 640  # video capture width\n",
    "IMG_H = 480  # video capture height\n",
    "IMG_BORDER = 40  # video capture border width (won't be used for detection)\n",
    "DETECT_THRESHOLD = 0.7  # only display digits with 70%+ probability \n",
    "CONTOUR_COLOR = (0, 255, 255)  # digit frame color\n",
    "LABEL_COLOR = (255, 255, 0)  # digit label color\n",
    "LABEL_SIZE = 0.7  # digit label size (70%)\n",
    "RUNTIME_ONLY = True  # use TF Lite runtime instead of Tensorflow\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load TF Lite model\n",
    "if RUNTIME_ONLY:\n",
    "    from tflite_runtime.interpreter import Interpreter\n",
    "    interpreter = Interpreter(model_path=TF_LITE_MODEL)\n",
    "else:\n",
    "    import tensorflow as tf\n",
    "    interpreter = tf.lite.Interpreter(model_path=TF_LITE_MODEL)\n",
    "\n",
    "# prepare model\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# get input shape\n",
    "INPUT_H, INPUT_W = input_details[0]['shape'][1:3]\n",
    "\n",
    "# kernel for morphological closing\n",
    "MORPH_KERNEL = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "\n",
    "# start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, IMG_W)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, IMG_H)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # get one frame\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    # convert to gray\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # image thresholding (to black and white)\n",
    "    _, frame_binary = cv2.threshold(frame_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "    \n",
    "    # do morphological closing to filter out noise\n",
    "    frame_binary = cv2.morphologyEx(frame_binary, cv2.MORPH_CLOSE, MORPH_KERNEL)\n",
    "    \n",
    "    # find contours (possible digits area) in the frame\n",
    "    contours, _ = cv2.findContours(frame_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # iterate all contours\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # if the area is overlapping the border, ignore it\n",
    "        if x < IMG_BORDER or x + w > (IMG_W - 1) - IMG_BORDER or y < IMG_BORDER or y + h > (IMG_H - 1) - IMG_BORDER:\n",
    "            continue\n",
    "        \n",
    "        # if the area is too small or too large, ignore it\n",
    "        if w < INPUT_W // 2 or h < INPUT_H // 2 or w > IMG_W // 2 or h > IMG_H // 2:\n",
    "            continue\n",
    "        \n",
    "        # get the image from the area\n",
    "        img = frame_binary[y: y + h, x: x + w]\n",
    "        \n",
    "        # add padding to make the image square with extra border\n",
    "        r = max(w, h)\n",
    "        y_pad = ((w - h) // 2 if w > h else 0) + r // 5\n",
    "        x_pad = ((h - w) // 2 if h > w else 0) + r // 5\n",
    "        img = cv2.copyMakeBorder(img, top=y_pad, bottom=y_pad, left=x_pad, right=x_pad, borderType=cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        \n",
    "        # resize image to input size\n",
    "        img = cv2.resize(img, (INPUT_W, INPUT_H), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # make prediction\n",
    "        interpreter.set_tensor(input_details[0]['index'], np.expand_dims(img, axis=0))\n",
    "        interpreter.invoke()\n",
    "        predicted = interpreter.get_tensor(output_details[0]['index']).flatten()\n",
    "        \n",
    "        # get label and probability\n",
    "        label = predicted.argmax(axis=0)\n",
    "        prob = predicted[label]\n",
    "        \n",
    "        # ignore it if probability is below the threshold\n",
    "        if prob < DETECT_THRESHOLD:\n",
    "            continue\n",
    "        \n",
    "        # draw rectangle and text label around the image area\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), CONTOUR_COLOR, 2)\n",
    "        cv2.putText(frame, str(label), (x + w // 5, y - h // 5), cv2.FONT_HERSHEY_COMPLEX, LABEL_SIZE, LABEL_COLOR, 2)\n",
    "    \n",
    "    # display the frame\n",
    "    cv2.imshow('MNIST Live Detection', frame)\n",
    "    \n",
    "    # exit video capture if user press 'q'\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEAM教學網：\n",
    "使用 Keras 搭配 NumPy 訓練手寫數字模型，再搭配 OpenCV KNN 演算方法 ( cv2.ml.KNearest_load )，即時辨識出手寫的阿拉伯數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "training...\n",
      "ok\n",
      "testing...\n",
      "0.9688\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras import utils\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()  # 載入訓練集\n",
    "\n",
    "# 訓練集資料\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)  # 轉換資料形狀\n",
    "x_train = x_train.astype('float32')/255         # 轉換資料型別\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "# 測試集資料\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)     # 轉換資料形狀\n",
    "x_test = x_test.astype('float32')/255           # 轉換資料型別\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "knn=cv2.ml.KNearest_create()                    # 建立 KNN 訓練方法\n",
    "knn.setDefaultK(5)                              # 參數設定\n",
    "knn.setIsClassifier(True)\n",
    "\n",
    "print('training...')\n",
    "knn.train(x_train, cv2.ml.ROW_SAMPLE, y_train)  # 開始訓練\n",
    "knn.save('mnist_knn.xml')                       # 儲存訓練模型\n",
    "print('ok')\n",
    "\n",
    "print('testing...')\n",
    "test_pre = knn.predict(x_test)                  # 讀取測試集並進行辨識\n",
    "test_ret = test_pre[1]\n",
    "test_ret = test_ret.reshape(-1,)\n",
    "test_sum = (test_ret == y_test)\n",
    "acc = test_sum.mean()                           # 得到準確率\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下方程式可運行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "start...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)                     # 啟用攝影鏡頭\n",
    "print('loading...')\n",
    "knn = cv2.ml.KNearest_load('mnist_knn.xml')   # 載入模型\n",
    "print('start...')\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Cannot receive frame\")\n",
    "        break\n",
    "    img = cv2.resize(img,(540,300))          # 改變影像尺寸，加快處理效率\n",
    "    x, y, w, h = 400, 200, 60, 60            # 定義擷取數字的區域位置和大小\n",
    "    img_num = img.copy()                     # 複製一個影像作為辨識使用\n",
    "    img_num = img_num[y:y+h, x:x+w]          # 擷取辨識的區域\n",
    "\n",
    "    img_num = cv2.cvtColor(img_num, cv2.COLOR_BGR2GRAY)    # 顏色轉成灰階\n",
    "    # 針對白色文字，做二值化黑白轉換，轉成黑底白字\n",
    "    ret, img_num = cv2.threshold(img_num, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    output = cv2.cvtColor(img_num, cv2.COLOR_GRAY2BGR)     # 顏色轉成彩色\n",
    "    img[0:60, 480:540] = output                            # 將轉換後的影像顯示在畫面右上角\n",
    "\n",
    "    img_num = cv2.resize(img_num,(28,28))   # 縮小成 28x28，和訓練模型對照\n",
    "    img_num = img_num.astype(np.float32)    # 轉換格式\n",
    "    img_num = img_num.reshape(-1,)          # 打散成一維陣列資料，轉換成辨識使用的格式\n",
    "    img_num = img_num.reshape(1,-1)\n",
    "    img_num = img_num/255\n",
    "    img_pre = knn.predict(img_num)          # 進行辨識\n",
    "    num = str(int(img_pre[1][0][0]))        # 取得辨識結果\n",
    "\n",
    "    text = num                              # 印出的文字內容\n",
    "    org = (x,y-20)                          # 印出的文字位置\n",
    "    fontFace = cv2.FONT_HERSHEY_SIMPLEX     # 印出的文字字體\n",
    "    fontScale = 2                           # 印出的文字大小\n",
    "    color = (0,0,255)                       # 印出的文字顏色\n",
    "    thickness = 2                           # 印出的文字邊框粗細\n",
    "    lineType = cv2.LINE_AA                  # 印出的文字邊框樣式\n",
    "    cv2.putText(img, text, org, fontFace, fontScale, color, thickness, lineType) # 印出文字\n",
    "\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),3)  # 標記辨識的區域\n",
    "    cv2.imshow('oxxostudio', img)\n",
    "    if cv2.waitKey(50) == ord('q'):\n",
    "        break     # 按下 q 鍵停止\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCD屏幕數字識別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# 导入一些python包\n",
    "from imutils.perspective import four_point_transform\n",
    "from imutils import contours\n",
    "import imutils\n",
    "import cv2\n",
    " \n",
    "# 定义每一个数字对应的字段\n",
    "DIGITS_LOOKUP = {\n",
    "    (1, 1, 1, 0, 1, 1, 1): 0,\n",
    "    (0, 0, 1, 0, 0, 1, 0): 1,\n",
    "    (1, 0, 1, 1, 1, 1, 0): 2,\n",
    "    (1, 0, 1, 1, 0, 1, 1): 3,\n",
    "    (0, 1, 1, 1, 0, 1, 0): 4,\n",
    "    (1, 1, 0, 1, 0, 1, 1): 5,\n",
    "    (1, 1, 0, 1, 1, 1, 1): 6,\n",
    "    (1, 0, 1, 0, 0, 1, 0): 7,\n",
    "    (1, 1, 1, 1, 1, 1, 1): 8,\n",
    "    (1, 1, 1, 1, 0, 1, 1): 9\n",
    "}\n",
    " \n",
    "# 读取输入图片\n",
    "image = cv2.imread(\"example.jpg\")\n",
    " \n",
    "# 将输入图片裁剪到固定大小\n",
    "image = imutils.resize(image, height=500)\n",
    "# 将输入转换为灰度图片\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# 进行高斯模糊操作\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "# 执行边缘检测\n",
    "edged = cv2.Canny(blurred, 50, 200, 255)\n",
    "cv2.imwrite('edge.png', edged)\n",
    " \n",
    "# 在边缘检测map中发现轮廓\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "# 根据大小对这些轮廓进行排序\n",
    "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "displayCnt = None\n",
    " \n",
    "# 循环遍历所有的轮廓\n",
    "for c in cnts:\n",
    "    # 对轮廓进行近似\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    " \n",
    "    # 如果当前的轮廓有4个顶点，我们返回这个结果，即LCD所在的位置\n",
    "    if len(approx) == 4:\n",
    "        displayCnt = approx\n",
    "        break\n",
    " \n",
    "# 应用视角变换到LCD屏幕上\n",
    "warped = four_point_transform(gray, displayCnt.reshape(4, 2))\n",
    "cv2.imwrite('warped.png', warped)\n",
    "output = four_point_transform(image, displayCnt.reshape(4, 2))\n",
    " \n",
    "# 使用阈值进行二值化\n",
    "thresh = cv2.threshold(warped, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "cv2.imwrite('thresh1.png', thresh)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1, 5))\n",
    "# 使用形态学操作进行处理\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imwrite('thresh2.png', thresh)\n",
    " \n",
    "# 在阈值图像中查找轮廓，然后初始化数字轮廓列表\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "digitCnts = []\n",
    " \n",
    "# 循环遍历所有的候选区域\n",
    "for c in cnts:\n",
    "    # 计算轮廓的边界框\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    " \n",
    "    # 如果当前的这个轮廓区域足够大，它一定是一个数字区域\n",
    "    if w >= 15 and (h >= 30 and h <= 40):\n",
    "        digitCnts.append(c)\n",
    " \n",
    "# 从左到右对这些轮廓进行排序\n",
    "digitCnts = contours.sort_contours(digitCnts, method=\"left-to-right\")[0]\n",
    "digits = []\n",
    " \n",
    "# 循环处理每一个数字\n",
    "i = 0\n",
    "for c in digitCnts:\n",
    "    # 获取ROI区域\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    roi = thresh[y:y + h, x:x + w]\n",
    " \n",
    "    # 分别计算每一段的宽度和高度\n",
    "    (roiH, roiW) = roi.shape\n",
    "    (dW, dH) = (int(roiW * 0.25), int(roiH * 0.15))\n",
    "    dHC = int(roiH * 0.05)\n",
    " \n",
    "    # 定义一个7段数码管的集合\n",
    "    segments = [\n",
    "        ((0, 0), (w, dH)),               # 上\n",
    "        ((0, 0), (dW, h // 2)),           # 左上\n",
    "        ((w - dW, 0), (w, h // 2)),          # 右上\n",
    "        ((0, (h // 2) - dHC) , (w, (h // 2) + dHC)), # 中间\n",
    "        ((0, h // 2), (dW, h)),            # 左下\n",
    "        ((w - dW, h // 2), (w, h)),          # 右下\n",
    "        ((0, h - dH), (w, h))              # 下\n",
    "    ]\n",
    "    on = [0] * len(segments)\n",
    " \n",
    "    # 循环遍历数码管中的每一段\n",
    "    for (i, ((xA, yA), (xB, yB))) in enumerate(segments): # 检测分割后的ROI区域，并统计分割图中的阈值像素点\n",
    "        segROI = roi[yA:yB, xA:xB]\n",
    "        total = cv2.countNonZero(segROI)\n",
    "        area = (xB - xA) * (yB - yA)\n",
    " \n",
    "        # 如果非零区域的个数大于整个区域的一半，则认为该段是亮的\n",
    "        if total / float(area) > 0.5:\n",
    "            on[i]= 1\n",
    " \n",
    "    # 进行数字查询并显示结果\n",
    "    digit = DIGITS_LOOKUP[tuple(on)]\n",
    "    digits.append(digit)\n",
    "    cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "    cv2.putText(output, str(digit), (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0), 2)\n",
    " \n",
    "# 显示最终的输出结果\n",
    "print(u\"{}{}.{} \\u00b0C\".format(*digits))\n",
    "cv2.imshow(\"Input\", image)\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
